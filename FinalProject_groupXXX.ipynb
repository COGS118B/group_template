{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 118B - Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Insert title here\n",
    "\n",
    "## Group members\n",
    "\n",
    "- Nikita Cardozo\n",
    "- Divinity Gines\n",
    "- Mia Le\n",
    "- Boden Haber\n",
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract \n",
    "This section should be short and clearly stated. It should be a single paragraph <200 words.  It should summarize: \n",
    "- what your goal/problem is\n",
    "- what the data used represents \n",
    "- the solution/what you did\n",
    "- major results you came up with (mention how results are measured) \n",
    "\n",
    "__NB:__ this final project form is much more report-like than the proposal and the checkpoint. Think in terms of writing a paper with bits of code in the middle to make the plots/tables"
    "The goal for this project is to be able to predict who the next super bowl winner is based on their stats. The first dataset is the NFL team stats from 1998-2019. These are the logged stats of each team in the NFL per season. It includes the number of wins, losses, yards, and more. The second dataset is the super bowl teams. This includes the winner, loser, points, and location. We will be using the team stats and the winners of the super bowls to create a prediction model in order to predict who winner of the superbowl is based off their season stats. This means that we would need to break our dataset into a training set, validation set, and test set. Performance/success would be measured based on if it is accurately able to predict the superbowl winners of previous years."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "\n",
    "Fill in the background and discuss the kind of prior work that has gone on in this research area here. **Use inline citation** to specify which references support which statements.  You can do that through HTML footnotes (demonstrated here). I used to reccommend Markdown footnotes (google is your friend) because they are simpler but recently I have had some problems with them working for me whereas HTML ones always work so far. So use the method that works for you, but do use inline citations.\n",
    "\n",
    "Here is an example of inline citation. After government genocide in the 20th century, real birds were replaced with surveillance drones designed to look just like birds<a name=\"lorenz\"></a>[<sup>[1]</sup>](#lorenznote). Use a minimum of 2 or 3 citations, but we prefer more <a name=\"admonish\"></a>[<sup>[2]</sup>](#admonishnote). You need enough citations to fully explain and back up important facts. \n",
    "\n",
    "Remeber you are trying to explain why someone would want to answer your question or why your hypothesis is in the form that you've stated. "
    "\n"
    "With all of the different ways to predict a super bowl winner out on the internet, whether that be through puppies prediciting the winner or conspiracies such as whoever is the bottom color of the super bowl logo, we wanted to see if there was a way to use machine learning to accurately predict who the winner of the super bowl is, and in turn the score of the super bowl game. There are a variety of different machine learning algorithms that can be used to accurately predict sports. We found that there has been some research on using machine learning to predict sports outcomes. We start to look at the different machine learning algorithms and which would best be used for sports. There has been better accuracy  with neural networks in regards to sports predictions and these are not dependent on the number of seasons that are included in the data <a name =\"horvat\"></a>[<sup>[1]</sup>](#horvatnote). Each sport also has a specific algorithm that works best for the sport, where football was best predicted using CART or ANN trained with BP <a name=\"bunker\"></a>[<sup>[2]</sup>](#bunkernote). This led to seeing that for football,  classification models predict game outcomes better than regression models <a name=\"dursun\"></a>[<sup>[3]</sup>](#dursunnote). A lot of the research done on sports predictions focus on the winner of the game. We wanted to go more indepth and see if we can find a way to more accurately predict the winner by also predicting the score of the game and go beyond that to find if we can predict who ends up at the super bowl based off their stats."

   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "Our problem is figuring out who will win the next Superbowl. \n",
    "We are trying to develop a model to take in historical NFL data, including team and player performance metrics, injuries, trades and other factors (weather conditions, home advantage). \n",
    "We will accurately estimate the winning probabilities for each team. \n",
    "By using historical data and ML tecniques for predictive analysis, we will be able to predict a winner combined with various influencing factors. \n",
    "The problem will also utilize a vast array of datasets to predict the winner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "Detail how/where you obtained the data and cleaned it (if necessary)\n",
    "\n",
    "If the data cleaning process is very long (e.g., elaborate text processing) consider describing it briefly here in text, and moving the actual clearning process to another notebook in your repo (include a link here!).  The idea behind this approach: this is a report, and if you blow up the flow of the report to include a lot of code it makes it hard to read.\n",
    "\n",
    "Please give the following infomration for each dataset you are using\n",
    "- link/reference to obtain it\n",
    "- description of the size of the dataset (# of variables, # of observations)\n",
    "- what an observation consists of\n",
    "- what some critical variables are, how they are represented\n",
    "- any special handling, transformations, cleaning, etc you have done should be demonstrated here!\n"
    "Some data we will use: Superbowl History of past wins, How each team is doing in the regular season information about players on each team (their stats), points scored during the season, how many touchdowns scored. \n",
    "\n",    
    "Dataset1: https://www.kaggle.com/datasets/ttalbitt/american-football-team-stats-1998-2019 \n",
     "Team-by-team dataset; row is team from a year and columns are season stats for the year. 63 columns with 669 unique values. \n",
     "Each row has the team with the year, followed by # of wins, # of losses, # PF, #yards, #plays, #fumbles, #1st downs. 'n",
     "We will need which teams has highest number of wins and for those with losses by how much. \n",
     "\n",
    "Dataset2: https://www.kaggle.com/datasets/timoboz/superbowl-history-1967-2020. \n",
    "Data about Superbowl finals from 1967 to 2020. Each row is each superbowl. \n", 
    "10 columns: Date, Superbowl Title, Winner, #Winner points, Loser, #loser points, MVP, Stadium, City, State \n", 
    "Shows all information about each superbowl; represented in strings and numbers \n", 
    "We mostly just need the values of who won the Superbowl and maybe by how many points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proposed Solution\n",
    "\n",
    "In this section, clearly describe a solution to the problem. The solution should be applicable to the project domain and appropriate for the dataset(s) or input(s) given. Provide enough detail (e.g., algorithmic description and/or theoretical properties) to convince us that your solution is applicable. Make sure to describe how the solution will be tested.  \n",
    "\n",
    "If you know details already, describe how (e.g., library used, function calls) you plan to implement the solution in a way that is reproducible.\n",
    "\n",
    "If it is appropriate to the problem statement, describe a benchmark model<a name=\"sota\"></a>[<sup>[3]</sup>](#sotanote) against which your solution will be compared.\n "
    "Our goal within this project is to aggregate all of the data from the past superbowl winners as well as current statistics to help predict who the next Super Bowl winner will be. We plan on using dimensionality reduction to help eliminate less important features and filter out any of the noise in the data. By reducing the dimensionality it will also help us when we use clustering algorithms by making the computation more efficient for us. Once we have done dimensionality reduction we plan on clustering the data by grouping teams based on similarities in a variety of performance metrics as well as characteristics. We are hoping to identify certain patterns that could indicate potential for Super Bowl success. Some dimensions that the data may be clustered by is offensive and defensive strategies, key player statistics, past playoff performance, and more.After doing our clustering we want to look at the identifying characteristics and performance metrics of each cluster to see how the clusters differentiate themselves. We are going to be looking at the key features that Super Bowl winners have within specific clusters. Then we will do  testing that  will use internal validation such as a silhouette score to assess the quality of the clusters formed, allowing us to see how similar a data point is in their cluster. We can then use those insights that we have gained from the clustering to develop predictive models to see the likelihood of which team will win the Super Bowl.  \n",

   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics\n",
    "\n",
    "Propose at least one evaluation metric that can be used to quantify the performance of both the benchmark model and the solution model. The evaluation metric(s) you propose should be appropriate given the context of the data, the problem statement, and the intended solution. Describe how the evaluation metric(s) are derived and provide an example of their mathematical representations (if applicable). Complex evaluation metrics should be clearly defined and quantifiable (can be expressed in mathematical or logical terms).\n"
    "For our evaluation metrics, we can use a few measurements to evaluate both the benchmark model and the solution model. For our classification model, where we are making our predictions for teams that will win the superbowl, we can use accuracy as the most straightforward evaluation metric, and calculate the proportion of correct predictions (both true positives and true negatives) out of all predictions. We can also use precision and recall to  ​​measure the proportion of positive identifications that were actually correct, and the proportion of actual positives that were identified correctly. These measurements will be particularly useful because incorrectly predicting a team as a Super Bowl winner when it's not is less desirable than missing a potential winner. For our unsupervised analysis, we’re thinking about using clustering for team profiling. Using K-means or hierarchical clustering to group teams into clusters based on their performance metrics. These clusters can help identify patterns of team performance that correlate with Super Bowl success. For example, teams within a cluster characterized by a strong defense and decent offensive scores might have a higher likelihood of winning the Super Bowl. For this model, we can use the silhouette score as our evaluation metric. This metric measures how similar an object is to its own cluster compared to other clusters. This score ranges from -1 to 1, where a high value indicates that the object is well matched to its own cluster and poorly matched to neighboring clusters. In the context of team profiling, a high silhouette score would indicate good clustering and that teams within a cluster are similar to one another and distinct from teams in other clusters."

   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "You may have done tons of work on this. Not all of it belongs here. \n",
    "\n",
    "Reports should have a __narrative__. Once you've looked through all your results over the quarter, decide on one main point and 2-4 secondary points you want us to understand. Include the detailed code and analysis results of those points only; you should spend more time/code/plots on your main point than the others.\n",
    "\n",
    "If you went down any blind alleys that you later decided to not pursue, please don't abuse the TAs time by throwing in 81 lines of code and 4 plots related to something you actually abandoned.  Consider deleting things that are not important to your narrative.  If its slightly relevant to the narrative or you just want us to know you tried something, you could keep it in by summarizing the result in this report in a sentence or two, moving the actual analysis to another file in your repo, and providing us a link to that file.\n",
    "\n",
    "### Subsection 1\n",
    "\n",
    "You will likely have different subsections as you go through your report. For instance you might start with an analysis of the dataset/problem and from there you might be able to draw out the kinds of algorithms that are / aren't appropriate to tackle the solution.  Or something else completely if this isn't the way your project works.\n",
    "\n",
    "### Subsection 2\n",
    "\n",
    "Another likely section is if you are doing any feature selection through cross-validation or hand-design/validation of features/transformations of the data\n",
    "\n",
    "### Subsection 3\n",
    "\n",
    "Probably you need to describe the base model and demonstrate its performance.  Maybe you include a learning curve to show whether you have enough data to do train/validate/test split or have to go to k-folds or LOOCV or ???\n",
    "\n",
    "### Subsection 4\n",
    "\n",
    "Perhaps some exploration of the model selection (hyper-parameters) or algorithm selection task. Validation curves, plots showing the variability of perfromance across folds of the cross-validation, etc. If you're doing one, the outcome of the null hypothesis test or parsimony principle check to show how you are selecting the best model.\n",
    "\n",
    "### Subsection 5 \n",
    "\n",
    "Maybe you do model selection again, but using a different kind of metric than before?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion\n",
    "\n",
    "### Interpreting the result\n",
    "\n",
    "OK, you've given us quite a bit of tech informaiton above, now its time to tell us what to pay attention to in all that.  Think clearly about your results, decide on one main point and 2-4 secondary points you want us to understand. Highlight HOW your results support those points.  You probably want 2-5 sentences per point.\n",
    "\n",
    "### Limitations\n",
    "\n",
    "Are there any problems with the work?  For instance would more data change the nature of the problem? Would it be good to explore more hyperparams than you had time for?   \n",
    "\n",
    "### Ethics & Privacy\n",
    "\n",
    "If your project has obvious potential concerns with ethics or data privacy discuss that here.  Almost every ML project put into production can have ethical implications if you use your imagination. Use your imagination.\n",
    "\n",
    "Even if you can't come up with an obvious ethical concern that should be addressed, you should know that a large number of ML projects that go into producation have unintended consequences and ethical problems once in production. How will your team address these issues?\n",
    "\n",
    "Consider a tool to help you address the potential issues such as https://deon.drivendata.org\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "Reiterate your main point and in just a few sentences tell us how your results support it. Mention how this work would fit in the background/context of other work in this field if you can. Suggest directions for future work if you want to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Footnotes\n",
    "<a name=\"lorenznote\"></a>1.[^](#lorenz): Lorenz, T. (9 Dec 2021) Birds Aren’t Real, or Are They? Inside a Gen Z Conspiracy Theory. *The New York Times*. https://www.nytimes.com/2021/12/09/technology/birds-arent-real-gen-z-misinformation.html<br> \n",
    "<a name=\"admonishnote\"></a>2.[^](#admonish): Also refs should be important to the background, not some randomly chosen vaguely related stuff. Include a web link if possible in refs as above.<br>\n",
    "<a name=\"sotanote\"></a>3.[^](#sota): Perhaps the current state of the art solution such as you see on [Papers with code](https://paperswithcode.com/sota). Or maybe not SOTA, but rather a standard textbook/Kaggle solution to this kind of problem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
